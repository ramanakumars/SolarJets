{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Jet clusters and exporting them\n",
    "## Need Aggregator files, Meta_data_subjects.json made during the aggregation in BoxTheJets\n",
    "This notebook takes the jets detected per subjects and looks for clusters in space and time. If two jets of different clusters fall within the epsilon given by the user (set by eps and time_eps) they are clustered together to make a jet cluster, this can be repeated such that more jets are added to the cluster. Clusters can only contain one jet per subject such that closeby jets are detected seperatly. \n",
    "The second part of this notebook requires the database of the Zooniverse to make the conversion between pixels ans solar coordinates. The meta data is saved in the Meta_data_subjects.json file complied from the solar-jet-hunter-subjects.csv file dowloaded during the aggregation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from aggregation import Aggregator, get_subject_image\n",
    "from aggregation import SOL\n",
    "from aggregation import MetaFile\n",
    "from aggregation import QuestionResult\n",
    "from aggregation import json_export_list\n",
    "from aggregation import get_box_edges, sigma_shape\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.dates import DateFormatter\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "plt.style.use('default')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator = Aggregator('reductions/point_reducer_hdbscan_box_the_jets.csv',\n",
    "                        'reductions/shape_reducer_dbscan_box_the_jets.csv')\n",
    "aggregator.load_classification_data('box-the-jets-classifications.csv')\n",
    "# aggregator.load_extractor_data('extracts/point_extractor_by_frame_box_the_jets.csv',\n",
    "#                                'extracts/shape_extractor_rotateRectangle_box_the_jets.csv')\n",
    "\n",
    "reducer_data = QuestionResult('../question_reducer_combined_workflows.csv')\n",
    "\n",
    "sol = SOL('../Meta_data_subjects.json', aggregator)\n",
    "\n",
    "metafile = MetaFile('../Meta_data_subjects.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                         | 1/323 [00:00<00:32,  9.95it/s]/home/rsankar/.conda/envs/solarjets/lib/python3.10/site-packages/shapely/set_operations.py:133: RuntimeWarning: invalid value encountered in intersection\n",
      "  return lib.intersection(a, b, **kwargs)\n",
      "  1%|▋                                                                                                         | 2/323 [00:01<03:18,  1.62it/s]/home/rsankar/zooniverse/projects/SolarJetHunter/SolarJetsclone/SolarJets/BoxTheJets/aggregation/SOL_class.py:445: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  point_metric[k, j] = point_dist / \\\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 323/323 [05:36<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "Jet_clusters = []\n",
    "# Set the space and time epsilon\n",
    "eps, time_eps = 3.0, 2.0\n",
    "\n",
    "for s in tqdm.tqdm(range(len(metafile.SOL_unique))):\n",
    "    del_index = np.array([], dtype=int)\n",
    "    SOL_event = metafile.SOL_unique[s]\n",
    "    try:\n",
    "        clusters, distance_met, point_met, box_met = sol.filter_jet_clusters(\n",
    "            SOL_event, eps=eps, time_eps=time_eps)\n",
    "    except:\n",
    "        continue\n",
    "    for j, cluster in enumerate(clusters):\n",
    "        cluster.adding_new_attr(\"SOL\", SOL_event)\n",
    "        if len(cluster.jets) == 1 and reducer_data.Agr_mask(reducer_data.get_data_by_id(cluster.jets[0].subject))[-1][0] == 'n':\n",
    "            # jets that only last 1 subject and do not have 50% agreement yes are excluded\n",
    "            del_index = np.append(del_index, j)\n",
    "    if len(del_index) > 0:\n",
    "        # print(f'Remove {len(del_index)} clusters from list due to too low agreement')\n",
    "        clusters = np.delete(clusters, del_index)\n",
    "    Jet_clusters.extend(clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this next part we will extract the Solar coordinates for the subject values. We use the Meta_data_subjects.json file to obtain the needed information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aggregation.image_handler import solar_conversion\n",
    "\n",
    "\n",
    "def get_solar_distance(subject_id, pair, metadata):\n",
    "    '''\n",
    "        Get the solar projected distance between the two pairs of X,Y coordinates\n",
    "            Inputs:\n",
    "            -------\n",
    "            subject_id : int\n",
    "                subject_id used in the Zooniverse subject\n",
    "            pair : np.array\n",
    "                x,y Coordinates of the two points 1,2 for which the solar distance needs to be calculated\n",
    "                format [[x1,y1],[x2,y2]]\n",
    "    '''\n",
    "    solw1 = solar_conversion(subject_id, pair[0][0], pair[0][1], metadata)\n",
    "    solw2 = solar_conversion(subject_id, pair[1][0], pair[1][1], metadata)\n",
    "    # Euclidean distance\n",
    "    distance = np.sqrt((solw1[0]-solw2[0])**2 + (solw1[1]-solw2[1])**2)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go through the list of jet clusters and determine their propeties in physical coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sjh_ID(obs_time,ID_list):\n",
    "    datestr = np.datetime_as_string(obs_time, unit='h')\n",
    "    number = 1\n",
    "    sjh_ID = 'sjh_'+datestr+'_'+str(number)\n",
    "    while sjh_ID in ID_list:\n",
    "        number+=1\n",
    "        sjh_ID = 'sjh_'+datestr+'_'+str(number)\n",
    "        \n",
    "    return sjh_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[981.6736712324777,\n",
       " 428.53948307808065,\n",
       " 115.7990122755364,\n",
       " 223.5588268888604,\n",
       " 3.14087441109926]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jet = Jet_clusters[0].jets[0]\n",
    "jet.cluster_values\n",
    "#{\"x\": 954.5914662641096, \"y\": 480.59115710736063, \"w\": 173.13948566787667, \"h\": 112.65634156348673, \"a\": 1.5707963266691043}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 881/881 [04:48<00:00,  3.05it/s]\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.getLogger('sunpy').setLevel(logging.CRITICAL)\n",
    "sjh_ID_list = []\n",
    "\n",
    "for C in tqdm.tqdm(Jet_clusters):\n",
    "    # print('Jet start')\n",
    "    H = []\n",
    "    W = []\n",
    "    A = []\n",
    "    X = []\n",
    "    Y = []\n",
    "    sig = []\n",
    "    H_sig = np.zeros((len(C.jets), 2))\n",
    "    obs_time = np.array([], dtype='datetime64')\n",
    "    end_time = np.array([], dtype='datetime64')\n",
    "    nextracts = 0\n",
    "    nclassifications = 0\n",
    "    for j, jet in enumerate(C.jets):\n",
    "        # print(j, len(C.jets))\n",
    "        width_pair, height_pair = jet.get_width_height_pairs()\n",
    "        # Find sigma of maximum height by first getting the pixel height\n",
    "        H_pix_box = np.sqrt((height_pair[1][0]-height_pair[0][0]) **\n",
    "                            2 + (height_pair[1][1]-height_pair[0][1])**2)\n",
    "        index = list(map(int, jet.cluster_values)).index(int(H_pix_box))\n",
    "        # Get the height of the box in pixels for the +-1 sigma\n",
    "        plus_sigma, minus_sigma = sigma_shape(jet.cluster_values, jet.sigma)\n",
    "        H_pix_minus = minus_sigma[index]\n",
    "        H_pix_plus = plus_sigma[index]\n",
    "        # print(width_pair,height_pair)\n",
    "        # Get the solar locations on the jet\n",
    "        metadata = metafile.get_subjectdata_by_id(jet.subject)\n",
    "        # file=metadata['#file_name_0']\n",
    "        try:\n",
    "            Bx, By = solar_conversion(jet.subject, jet.start[0], jet.start[1], metadata)\n",
    "        except:\n",
    "            print('This one breaks', jet.subject)\n",
    "            continue\n",
    "\n",
    "        nextracts += jet.nextracts\n",
    "        nclassifications += jet.nclassifications\n",
    "        \n",
    "        Ex, Ey = solar_conversion(jet.subject, jet.end[0], jet.end[1], metadata)\n",
    "        # print('Start base',Bx,By)\n",
    "        # print('sigma',jet.sigma)\n",
    "        # Add as attributes and as a list\n",
    "        jet.adding_new_attr(\"solar_start\", [Bx, By])\n",
    "        jet.adding_new_attr(\"solar_end\", [Ex, Ey])\n",
    "        sig.append(jet.sigma)\n",
    "        A.append(jet.cluster_values[-1])\n",
    "        X.append(Bx)\n",
    "        Y.append(By)\n",
    "        # Get the dates the subjecst were observed\n",
    "        O = metafile.get_subjectkeyvalue_by_id(jet.subject, 'startDate')\n",
    "        obs_time = np.append(obs_time, O)\n",
    "        E = metafile.get_subjectkeyvalue_by_id(jet.subject, 'endDate')\n",
    "        end_time = np.append(end_time, E)\n",
    "        # Calculate the height an wisth in arcsec\n",
    "        height = get_solar_distance(jet.subject, height_pair, metadata)\n",
    "        width = get_solar_distance(jet.subject, width_pair, metadata)\n",
    "        # Add as attributes and list\n",
    "        jet.adding_new_attr(\"solar_H\", height)\n",
    "        jet.adding_new_attr(\"solar_W\", width)\n",
    "        \n",
    "        #Add the box_cluster corner values in solar units\n",
    "        Box_x, Box_y = solar_conversion(jet.subject, jet.cluster_values[0], jet.cluster_values[1], metadata)\n",
    "        jet.adding_new_attr('solar_cluster_values', [Box_x, Box_y, width, height, jet.cluster_values[4]])\n",
    "        \n",
    "        H.append(height)\n",
    "        W.append(width)\n",
    "        # Get the error on the height by scaling the height with the (height_sigma/height -1)\n",
    "        err_plus, err_minus = height*(H_pix_plus/H_pix_box-1), height*(H_pix_minus/H_pix_box-1)\n",
    "        H_sig[j] = np.array([err_plus, err_minus])\n",
    "        jet.adding_new_attr(\"solar_H_sig\", [err_plus, err_minus])\n",
    "\n",
    "    duration = (end_time[-1]-obs_time[0])/np.timedelta64(1, 'm')\n",
    "    if obs_time[np.argmax(H)] == obs_time[0]:\n",
    "        vel = None\n",
    "    else:\n",
    "        vel = np.max(H)/((obs_time[np.argmax(H)]-obs_time[0]) / np.timedelta64(1, 's'))\n",
    "\n",
    "    sjh_ID = make_sjh_ID(obs_time[0],sjh_ID_list)\n",
    "    sjh_ID_list.append(sjh_ID)\n",
    "\n",
    "    C.adding_new_attr(\"ID\", sjh_ID)\n",
    "    C.adding_new_attr(\"event_probability\", nextracts / nclassifications)\n",
    "    C.adding_new_attr('Max_Height', np.max(H))\n",
    "    C.adding_new_attr('std_maxH', H_sig[np.argmax(H)])\n",
    "    C.adding_new_attr(\"Height\", np.average(H))\n",
    "    C.adding_new_attr(\"std_H\", np.std(H))\n",
    "    C.adding_new_attr(\"Width\", np.average(W))\n",
    "    C.adding_new_attr(\"std_W\", np.std(W))\n",
    "    C.adding_new_attr(\"Bx\", np.average(X))\n",
    "    C.adding_new_attr(\"std_Bx\", np.std(X))\n",
    "    C.adding_new_attr(\"By\", np.average(Y))\n",
    "    C.adding_new_attr(\"std_By\", np.std(Y))\n",
    "    C.adding_new_attr(\"obs_time\", obs_time[0])\n",
    "    C.adding_new_attr(\"sigma\", np.average(sig))\n",
    "    C.adding_new_attr(\"Duration\", duration)\n",
    "    C.adding_new_attr(\"Velocity\", vel)\n",
    "    C.adding_new_attr(\"Angle\", np.mean(A))\n",
    "    C.adding_new_attr(\"std_A\", np.std(A))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the longitude and latitude of the measured basepoints as properties to the Jet_cluster objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "import sunpy.map\n",
    "from sunpy.coordinates import frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 881/881 [00:09<00:00, 90.60it/s]\n"
     ]
    }
   ],
   "source": [
    "for C in tqdm.tqdm(Jet_clusters):\n",
    "    # print(C.Bx,C.By)\n",
    "    X, Y = C.Bx, C.By\n",
    "    sky_coord = SkyCoord(X*u.arcsec, Y*u.arcsec, frame=frames.Helioprojective(observer=\"earth\",\n",
    "                                                                              obstime=str(C.obs_time)))\n",
    "    # print(sky_coord.heliographic_stonyhurst)\n",
    "    Coord = sky_coord.heliographic_stonyhurst\n",
    "    if np.isnan(Coord.lat):\n",
    "        # print('Coordinates off limb')\n",
    "        with frames.Helioprojective.assume_spherical_screen(sky_coord.observer):\n",
    "            # print(sky_coord.heliographic_stonyhurst)\n",
    "            Coord = sky_coord.heliographic_stonyhurst\n",
    "            C.adding_new_attr(\"Lat\", float(str(Coord.lat).split('d')[0]))\n",
    "            C.adding_new_attr(\"Lon\", float(str(Coord.lon).split('d')[0]))\n",
    "\n",
    "    else:\n",
    "        C.adding_new_attr(\"Lat\", float(str(Coord.lat).split('d')[0]))\n",
    "        C.adding_new_attr(\"Lon\", float(str(Coord.lon).split('d')[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flagging\n",
    "We introduce three binary flags to indicate a higher uncertainty of our jet clusters. \n",
    "flag 100 means the jet cluster has a duration of less than 6 minutes, which for many corresponds to a jet cluster found in one Zooniverse subject. \n",
    "flag 010 means the velocity estimate could not be calculated because the maximum was reached in the first subject the jet was found in. \n",
    "flag 001 means the basepoint has a Longitude of higher than 90 degrees meaning the base point was found to be (slightly) off limb. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount Jet clusters with flags 345\n"
     ]
    }
   ],
   "source": [
    "# Flagging\n",
    "stat_dur = np.array([Jet_clusters[i].Duration for i in range(len(Jet_clusters))], dtype=float)\n",
    "stat_vel = np.array([Jet_clusters[i].Velocity for i in range(len(Jet_clusters))], dtype=float)\n",
    "stat_Lon = np.array([Jet_clusters[i].Lon for i in range(len(Jet_clusters))], dtype=float)\n",
    "\n",
    "flag1 = np.where(stat_dur < 6)[0]\n",
    "flag2 = np.where(np.isnan(stat_vel))[0]\n",
    "flag3 = np.where(np.abs(stat_Lon) > 90)[0]\n",
    "tel = 0\n",
    "flags = np.array([])\n",
    "\n",
    "for i in range(len(Jet_clusters)):\n",
    "    f1, f2, f3 = i in flag1, i in flag2, i in flag3\n",
    "    if f1 or f2 or f3:\n",
    "        flag = str(int(f1 == True))+str(int(f2 == True))+str(int(f3 == True))\n",
    "    else:\n",
    "        flag = '000'\n",
    "        tel += 1\n",
    "    flags = np.append(flags, flag)\n",
    "\n",
    "print('Amount Jet clusters with flags', tel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add flags as a attribute\n",
    "for i, C in enumerate(Jet_clusters):\n",
    "    C.flag = flags[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the results of the clustering\n",
    "Export the JetCluster objects to a JSON file\n",
    "or \n",
    "Export the results to a csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_export_folder():\n",
    "    path = 'exports/'\n",
    "    # check if folder for plots exists\n",
    "    isExist = os.path.exists(path)\n",
    "    if not isExist:\n",
    "        os.makedirs(path)\n",
    "        print(\"exports directory is created\")\n",
    "\n",
    "\n",
    "make_export_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 881 JetCluster objects are exported to exports/Jet_clusters_3.0_2.0_paperID_cluster_xy.json.\n"
     ]
    }
   ],
   "source": [
    "# Export all the JetCluster objects\n",
    "json_export_list(Jet_clusters, f'exports/Jet_clusters_{eps}_{time_eps}_paperID_cluster_xy')\n",
    "# Jet_clusters[0].json_export('output_single') #Export a single JetCluster object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = np.array([Jet_clusters[i].ID for i in range(len(Jet_clusters))], dtype=str)\n",
    "Cluster_date = np.array([Jet_clusters[i].obs_time for i in range(len(Jet_clusters))], dtype=str)\n",
    "Cluster_SOL = np.array([Jet_clusters[i].SOL for i in range(len(Jet_clusters))], dtype=str)\n",
    "stat_Bx = np.array([Jet_clusters[i].Bx for i in range(len(Jet_clusters))], dtype=str)\n",
    "stat_By = np.array([Jet_clusters[i].By for i in range(len(Jet_clusters))], dtype=str)\n",
    "stat_Lon = np.array([Jet_clusters[i].Lon for i in range(len(Jet_clusters))], dtype=str)\n",
    "stat_Lat = np.array([Jet_clusters[i].Lat for i in range(len(Jet_clusters))], dtype=str)\n",
    "stat_H = np.array([Jet_clusters[i].Max_Height for i in range(len(Jet_clusters))], dtype=str)\n",
    "stat_W = np.array([Jet_clusters[i].Width for i in range(len(Jet_clusters))], dtype=str)\n",
    "stat_dur = np.array([Jet_clusters[i].Duration for i in range(len(Jet_clusters))], dtype=str)\n",
    "stat_vel = np.array([Jet_clusters[i].Velocity for i in range(len(Jet_clusters))], dtype=str)\n",
    "stat_sigma = np.array([Jet_clusters[i].sigma for i in range(len(Jet_clusters))], dtype=str)\n",
    "std_H = np.array([Jet_clusters[i].std_maxH for i in range(len(Jet_clusters))], dtype=str)\n",
    "std_W = np.array([Jet_clusters[i].std_W for i in range(len(Jet_clusters))], dtype=str)\n",
    "std_Bx = np.array([Jet_clusters[i].std_Bx for i in range(len(Jet_clusters))], dtype=str)\n",
    "std_By = np.array([Jet_clusters[i].std_By for i in range(len(Jet_clusters))], dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile = open(f'exports/Jet_clusters_{eps}_{time_eps}_paperID.csv', 'w')\n",
    "csvfile.writelines('#sjh_ID, date, SOL_event, duration, basepoint_X, std_X, basepoint_Y, std_Y, basepoint_X_longitude, basepoint_Y_latitude, max_height, upper_H, lower_H, avg_width, std_width, velocity, sigma, flags')\n",
    "csvfile.writelines('\\n')\n",
    "with open(f'exports/Jet_clusters_{eps}_{time_eps}_paperID.csv', 'a') as csvfile:\n",
    "    np.savetxt(csvfile, np.column_stack((ID, Cluster_date, Cluster_SOL, stat_dur, stat_Bx, std_Bx, stat_By, std_By, stat_Lon,\n",
    "               stat_Lat, stat_H, std_H, stat_W, std_W, stat_vel, stat_sigma, flags)), delimiter=\",\", newline='\\n', fmt='%s')\n",
    "csvfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
